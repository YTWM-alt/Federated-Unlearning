下面把**你现在这份代码里的算法流程**按执行顺序完整梳理一遍（含关键设计与“为什么这么做”），你可以直接当成实现版的 spec 来看。

---

# 总体流程（入口到评测）

1. **准备数据与模型**

   * 读取数据集，按 `dirichlet` 或 `iid` 划分到各客户端，创建各自 DataLoader；测试集也创建好。
   * 构建初始全局模型 `global_model`（支持 AllCNN / ResNet18 / SmallCNN）。
2. **联邦训练**

   * 运行 `fed_train` 完整训练 `num_training_iterations` 轮，保存每一轮的各客户端权重到 `experiments/<exp_name>/full_training/iteration_t/client_i.pth`。
   * 评测训练后整体性能与各客户端精度。
3. **重训练（baseline）**

   * 从**保留客户端**（剔除要遗忘的客户端）数据再次训练得到 `retrained_global_model`；作为对照，打印整体与遗忘客户端精度。
4. **FAIR-VUE（我们的算法）**

   * 在 `--baselines fair_vue` 打开时执行，细节见下文分步。
   * 完成后评测整体性能和**遗忘客户端**精度。
5. **其他 baseline（可选）**

   * 代码还保留了 `PGA / FedEraser / FedFIM` 的钩子；**旧的 Legacy Unlearn**已通过开关关闭（默认不跑）。

---

# FAIR-VUE：实现细节（按代码实际执行顺序）

## A. 解析快照、构造逐轮增量 Δ

* 逐轮读取 `full_training/iteration_t/client_i.pth`，并**构造每轮每个客户端的更新**
  [
  \Delta_i^{(t)} ;=; \underbrace{w_{i}^{(t)}}*{\text{该客户端本轮权重}} ;-; \underbrace{\bar w^{(t-1)}}*{\text{上一轮所有客户端权重的均值≈全局起点}}
  ]
  这样保证 Δ 的**起点一致**（上一轮全局），方向稳定，不会把“上一轮全局变化”混入。返回字典 `round_client_deltas[r][cid] = Δ_i^{(r)}`。

* 将**目标客户端**（例如 id=6）的历史增量收集为 `target_deltas_list`（长度 T≈训练轮数），其余客户端的增量拼到 `other_deltas_list`。

> 备注：这一步只做“**几何信息**”的准备，不涉及模型前向或梯度。

## B. 只在“**参数空间**”操作，屏蔽 buffers

* 取 `param_keys = [name for name, p in fair_model.named_parameters() if p.requires_grad]`，后续所有**展平/回写**都只对这些 key 生效；BN 的 `running_mean/var` 等 **buffers 不改**，避免整体性能被无谓破坏。

## C. 目标数据上估计**对角 Fisher**

* 在目标客户端的 DataLoader 上，开启可求导，计算**经验 Fisher 对角**（每个参数一个非负权重）。用于给不同参数维度**加权**，强调敏感方向、抑制噪声维。

## D. Fisher 加权 + 低秩 PCA（SVD）

* 构造加权矩阵 (X_w\in\mathbb{R}^{T\times D_p})：对每条 `Δ_target^t` 按 `sqrt(Fisher)` 逐维加权；仅使用 `param_keys` 的拼接向量（维度 (D_p)）。
* 对 (X_w) 做去中心化 SVD，取**右奇异向量**前 `k=--fair_rank_k` 列，得到主方向矩阵 (V\in\mathbb{R}^{D_p\times k})。这些是**目标客户端**跨轮更新的主变化方向。

## E. 方向“特异性”打分 ρ 与阈值 τ

* 对每个基向量 (v\in V)，计算
  [
  \rho(v) = \text{mean}_{j\in\text{others}}\left|\langle \Delta_j, v\rangle\right|
  ]
  在**其他客户端**增量上的平均投影幅值；越小表示越“**特异（只属于目标）**”。
* 用 `--fair_tau_mode`（`median`/`mean`）得到阈值 τ，划分得到

  * **特异子空间** (V_{\text{spec}}={v,|,\rho(v)\le\tau})
  * **通用子空间** (V_{\text{comm}}={v,|,\rho(v)>\tau})。
* 若极端情况 (V_{\text{spec}}) 为空，代码**兜底**选取 1–2 个最小 ρ 的方向，保证能擦。

## F. 低内存投影（避免 D×D 矩阵）

* 对 (V_{\text{spec}}) 做 QR 分解得正交基 (Q\in\mathbb{R}^{D_p\times r})（r=|V_spec|）。
* **不显式构造** (P=I-QQ^\top)（会 OOM），而是用

  * 特异分量：(\text{spec}(x)=Q(Q^\top x))
  * 通用分量：(\text{keep}(x)=x-\text{spec}(x))。
    整个过程在 GPU 上进行，但只做 (D_p\times r) 的乘法，内存开销小。

## G. 只累计“目标客户端”的特异分量并擦除

* 初始化 `spec_total = 0`（维度 (D_p)）。
* 对每一轮 **若目标客户端出现**，取其参数向量增量 ( \Delta_{\text{target}}^{(r)} )，计算特异分量 (\text{spec}^{(r)}=Q(Q^\top \Delta_{\text{target}}^{(r)}))，并累加到 `spec_total`。
* 用**擦除强度** `--fair_erase_scale`（默认 0.25）从当前参数向量中扣除
  [
  \theta_{\text{new}} ;=; \theta_{\text{now}} ;-; \texttt{erase_scale}\cdot \text{spec_total}
  ]
* 只把**参数子向量**回写到 `state_dict`（buffers 原样保留），载入模型。

## H. 评测与调试

* 调用统一评测接口输出整体/分客户端/分类别精度；单独打印遗忘客户端精度。
* 若加 `--fair_vue_debug`，会打印：

  * 轮数 & Δ 规模；Fisher 统计（min/mean/max）；
  * (X_w) 形状、SVD 前 8 个奇异值；
  * ρ 的分布、τ、(|V_{\text{spec}}|)；
  * (Q) 的形状；
  * `used_rounds_for_target` 与 `||spec_total||` 等。
    这些量可以直观看到“**是否在动模型**”以及“**动了多少**”。

---

# 关键设计与理由（对照你关心的问题）

* **Δ 的定义**：采用 `client_t − mean_clients_{t−1}`，等价于以上一轮“全局起点”对齐各客户端更新，方向稳定、可比较，这是遗忘“某一客户端贡献”的前提。
* **Fisher 加权**：强调目标数据上“敏感”的参数维，降低噪声维的权重，让 PCA 找到更“有效”的方向。
* **特异/通用分离**：通过其他客户端的平均投影来度量“共享度”，用 `median/mean` 自适应阈值，必要时兜底，确保一定有可擦除子空间。
* **只在参数空间操作**：严格屏蔽 BN 等 **buffers**，避免“不小心把统计量改坏”导致整体崩塌（你前面的实验已经证明这一点非常关键）。
* **低秩投影实现**：用 (Q(Q^\top \cdot)) 代替 (P\cdot) 显式大矩阵，避免显存爆炸；且 r（特异维度）一般很小（例如 3–8）。
* **只累计目标客户端的特异分量**：避免“对所有客户端均值”做擦除而误伤共享主方向，让遗忘更聚焦、更有效。
* **擦除强度可调**：`--fair_erase_scale ∈ (0,1]` 控制影响范围；实验上先小后大，配合 `rank_k/τ` 微调“忘得多还是保得多”。

---

# 可调“旋钮”（你现在已有）

* `--fair_rank_k`：主方向数 k；大一些能覆盖更多差异，但也可能带来噪声。
* `--fair_tau_mode`：`median`（默认）或 `mean`；间接影响 (|V_{\text{spec}}|)。
* `--fair_fisher_batches`：Fisher 估计的 batch 数；增大更稳定。
* `--fair_erase_scale`：擦除强度；建议 0.2~0.6 微调。
* `--fair_vue_debug`：打开详细中间量打印，便于判断“为何效果强/弱”。

---

# 一句话版

> 先把目标客户端跨轮的**相对全局**更新做 Fisher 加权 PCA，找出**只属于目标**的少量方向；再把目标在这些方向上的累计“特异分量”**从当前模型参数里扣掉**（只扣参数，不动 buffers，低秩投影避免 OOM），最后评测。整个过程**不重训练**，但对目标客户端的性能打击显著。

如果你想，我可以顺手把这段流程整理成 README 的“方法”小节（带公式与参数解释），方便投放到仓库里。


Medical References:
1. None — DOI: file_0000000013f061fa90ad64437751725f
